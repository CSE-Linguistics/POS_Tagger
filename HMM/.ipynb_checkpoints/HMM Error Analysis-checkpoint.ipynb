{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Fold:1\n",
      "Accuracy:0.9495050185618039\n",
      "\n",
      "Evaluating Fold:2\n",
      "Accuracy:0.9505050815192361\n",
      "\n",
      "Evaluating Fold:3\n",
      "Accuracy:0.9546509545596595\n",
      "\n",
      "Confusion Matrix for Fold:3\n",
      "[[30697    38    20     5     0     0   155     1     0     0    46     9\n",
      "      0]\n",
      " [    0 19522    11   499     0     1  1132     3     1     4   177    18\n",
      "      0]\n",
      " [    1    84 37331   392     1   103   400     0   112   373   212    25\n",
      "      0]\n",
      " [    0   520   497 10813    32     9    14     0     0    33    18     5\n",
      "      0]\n",
      " [    0     0    40    14  9264     4     0     0     0     0     0     4\n",
      "      0]\n",
      " [    1   679    92    73    19 32611   944    11    29     1   155    41\n",
      "      0]\n",
      " [    2   899    15   131     2     1 63892    68    19    18  1391   116\n",
      "      0]\n",
      " [    0     1     0     0     0     0   115  4408     0     0     0     0\n",
      "      0]\n",
      " [    0    21   118    42     0   167   614     3  7925     4    18    11\n",
      "      0]\n",
      " [    0    63   380    77     0     0    12     0     0  5249     1     2\n",
      "      0]\n",
      " [    0   174    51    59     0     3  1168     1     3     3 38516    34\n",
      "      0]\n",
      " [   19     2     1     0     0     0    24     3     0     0     1   180\n",
      "      0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "  11468]]\n",
      "\n",
      "Evaluating Fold:4\n",
      "Accuracy:0.9542517185947139\n",
      "\n",
      "Evaluating Fold:5\n",
      "Accuracy:0.9503921995295678\n",
      "\n",
      "Per POS Accuracy\n",
      "[('.', 0.9997763697353709), ('ADJ', 0.8928703670524719), ('ADP', 0.9664216735973916), ('ADV', 0.8898095627589395), ('CONJ', 0.9943644989646405), ('DET', 0.9868339427378685), ('NOUN', 0.9217551295915923), ('NUM', 0.9706198736049483), ('PRON', 0.9840272428750962), ('PRT', 0.9004659894733313), ('VERB', 0.946046511627907), ('X', 0.3492063492063492), ('^', 1.0)]\n",
      "\n",
      "Per POS Recall for Fold:1\n",
      "[('.', 0.9923254390508027), ('ADJ', 0.9006373570765913), ('ADP', 0.9417533892486436), ('ADV', 0.904509715318572), ('CONJ', 0.9925173983569672), ('DET', 0.9441003763414583), ('NOUN', 0.9563644167990782), ('NUM', 0.9706198736049483), ('PRON', 0.9117647058823529), ('PRT', 0.9016448472641826), ('VERB', 0.9605053361407563), ('X', 0.6904422253922967), ('^', 1.0)]\n",
      "Average Accuracy:0.951912629294922\n",
      "58371\n",
      "32441\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from nltk.corpus import brown\n",
    "\n",
    "def mylog(x):\n",
    "    if x==0:\n",
    "        return -1e5\n",
    "    else:\n",
    "        return np.log10(x)\n",
    "\n",
    "class HMM:\n",
    "    \n",
    "    unseen_words = 0\n",
    "    unseen_correct = 0\n",
    "    unseen_diction = {}\n",
    "    #Preprocess dataset: train and test\n",
    "    def __init__(self, train_data, test_data):\n",
    "        \n",
    "        '''\n",
    "            train_corpus: processed train_data\n",
    "            test_corpus : processed test_data\n",
    "        '''\n",
    "        \n",
    "        self.train_corpus = []\n",
    "        for i in range(len(train_data)):\n",
    "            sent = []\n",
    "            sent.append((\"^\", \"^\"))\n",
    "            sent = sent + [(re.sub('\\d{1,}', '0', w), t) for (w, t) in train_data[i]]\n",
    "            self.train_corpus.append(sent)\n",
    "        \n",
    "        self.test_corpus = []\n",
    "        for i in range(len(test_data)):\n",
    "            sent = []\n",
    "            sent.append((\"^\", \"^\"))\n",
    "            sent = sent + test_data[i]\n",
    "            self.test_corpus.append(sent)\n",
    "        \n",
    "    #Train HMM\n",
    "    def train(self):\n",
    "        '''\n",
    "            all_tags: contains all tags in the corpus\n",
    "            tags_freq: frequency of individual tags\n",
    "            tags_to_num: tags to index\n",
    "            num_to_tags: index to tags\n",
    "            all_words: all words in the corpus\n",
    "            transition: transition probabilities\n",
    "            emission: emission probabilities\n",
    "        '''\n",
    "        \n",
    "        #All tags in the train corpus\n",
    "        self.all_tags = []\n",
    "        for sent in self.train_corpus:\n",
    "            for (w, t) in sent:\n",
    "                if t not in self.all_tags:\n",
    "                    self.all_tags.append(t)\n",
    "        \n",
    "        self.all_tags.sort()\n",
    "        #Count frequency for each tag\n",
    "        self.tags_freq = {}\n",
    "        for t in self.all_tags:\n",
    "            self.tags_freq[t] = 0\n",
    "        for sent in self.train_corpus:\n",
    "            for (w, t) in sent:\n",
    "                self.tags_freq[t] += 1\n",
    "        \n",
    "        #length of corpus\n",
    "        self.total_tag = 0\n",
    "        for t in self.all_tags:\n",
    "            self.total_tag += self.tags_freq[t]\n",
    "\n",
    "        #tag to number and vice-versa\n",
    "        self.tags_to_num = {}\n",
    "        self.num_to_tags = {}\n",
    "        for i in range(len(self.all_tags)):\n",
    "            self.tags_to_num[self.all_tags[i]] = i\n",
    "            self.num_to_tags[i] = self.all_tags[i]\n",
    "\n",
    "        #All possible words in the set\n",
    "        self.all_words = set()\n",
    "        for sent in self.train_corpus:\n",
    "            for (w, t) in sent:\n",
    "                self.all_words.add(w)\n",
    "\n",
    "        #Count frequency for each (word, tag)\n",
    "        word_tag_freq = {}\n",
    "        for w in self.all_words:\n",
    "            for t in self.all_tags:\n",
    "                word_tag_freq[(w, t)] = 0\n",
    "        for sent in self.train_corpus:\n",
    "            for (w, t) in sent:\n",
    "                word_tag_freq[(w, t)] += 1\n",
    "\n",
    "        #evaluate transition  counts\n",
    "        self.transition = {}\n",
    "        for t1 in self.all_tags:\n",
    "            for t2 in self.all_tags:\n",
    "                self.transition[(t1, t2)] = 0\n",
    "        for sent in self.train_corpus:\n",
    "            for i in range(len(sent)-1):\n",
    "                self.transition[(sent[i][1], sent[i+1][1])] += 1\n",
    "\n",
    "        #evaluate transition and emission probabilities\n",
    "        self.emission = {}\n",
    "        for (t1, t2) in self.transition.keys():\n",
    "            self.transition[(t1, t2)] /= self.tags_freq[t1]\n",
    "        for (w, t) in word_tag_freq.keys():\n",
    "            self.emission[(w, t)] = word_tag_freq[(w, t)]/self.tags_freq[t]\n",
    "    \n",
    "    \n",
    "    #Implements Viterbi Algorithm\n",
    "    def viterbi(self, sent):\n",
    "        '''\n",
    "            sent: input sentence\n",
    "            returns predicted tags\n",
    "        '''\n",
    "        # Replace all numbers by 0\n",
    "        sentence = [re.sub('\\d{1,}', '0', w) for w in sent]\n",
    "            \n",
    "        len_sent = len(sentence)\n",
    "        len_tagset = len(self.all_tags)\n",
    "\n",
    "        #SEQSCORE and BACKPTR arrays\n",
    "        SEQSCORE = [[mylog(0) for i in range(len_sent)] for j in range(len_tagset)]\n",
    "        BACKPTR =  [[0 for i in range(len_sent)] for j in range(len_tagset)]\n",
    "\n",
    "        null_tag = self.tags_to_num[\"^\"]\n",
    "        #initialise the null tag\n",
    "        SEQSCORE[null_tag][0] = 0\n",
    "\n",
    "        for i in range(1, len_sent):#Corresponds to a given word sentence[i]\n",
    "            for cidx, ctag in enumerate(self.all_tags):#Ending at current tag\n",
    "\n",
    "                optimal_prob = -1e9 #Includes transitional probabilites\n",
    "                optimal_tag = 0\n",
    "\n",
    "                for pidx, ptag in enumerate(self.all_tags):#Previous tag\n",
    "                    prob_k_j_i = SEQSCORE[pidx][i-1] + mylog(self.transition[(ptag, ctag)])\n",
    "                    if prob_k_j_i > optimal_prob:\n",
    "                        optimal_prob = prob_k_j_i\n",
    "                        optimal_tag = pidx\n",
    "\n",
    "                if sentence[i] in self.all_words:\n",
    "                    SEQSCORE[cidx][i] = optimal_prob + mylog(self.emission[(sentence[i], ctag)])\n",
    "                else:\n",
    "                    SEQSCORE[cidx][i] = optimal_prob\n",
    "                BACKPTR[cidx][i] = optimal_tag\n",
    "\n",
    "        #Sequence identification step\n",
    "        CT = 0\n",
    "        optimal_prob = -1e9\n",
    "        for i in range(len_tagset):\n",
    "            if SEQSCORE[i][len_sent-1]>optimal_prob:\n",
    "                optimal_prob = SEQSCORE[i][len_sent-1]\n",
    "                CT = i\n",
    "        \n",
    "        pred_tags = [CT for i in range(len_sent)]\n",
    "        for i in reversed(range(len_sent-1)):\n",
    "            pred_tags[i] = BACKPTR[pred_tags[i+1]][i+1]\n",
    "\n",
    "        pred_tags = [self.num_to_tags[idx] for idx in pred_tags]\n",
    "        return pred_tags\n",
    "    \n",
    "    def evaluation(self):\n",
    "        '''\n",
    "            Returns evaluation metrics on the train_corpus\n",
    "        '''\n",
    "        len_tagset = len(self.all_tags)\n",
    "            \n",
    "        confusion_matrix = np.zeros((len_tagset, len_tagset), dtype = np.int32)\n",
    "        \n",
    "        for sent in self.test_corpus:\n",
    "            #Untagged Sentence\n",
    "            untagged_sent = []\n",
    "            for (w, t) in sent:\n",
    "                untagged_sent.append(w)\n",
    "    \n",
    "            predicted_tags = self.viterbi(untagged_sent)\n",
    "            \n",
    "            for i in range(len(sent)):\n",
    "                if sent[i][0] not in self.all_words:\n",
    "                    HMM.unseen_words += 1\n",
    "                    HMM.unseen_correct += int(predicted_tags[i]==sent[i][1])\n",
    "                confusion_matrix[self.tags_to_num[predicted_tags[i]]][self.tags_to_num[sent[i][1]]] += 1\n",
    "        \n",
    "        accuracy = np.trace(confusion_matrix)/np.sum(confusion_matrix)\n",
    "        return accuracy, confusion_matrix\n",
    "\n",
    "    \n",
    "corpora = brown.tagged_sents(tagset='universal')\n",
    "num_folds = 5\n",
    "num_tags = 13\n",
    "all_tags = {}\n",
    "subset_size = int(len(corpora)/num_folds)\n",
    "sum_confusion_matrix = np.zeros((num_tags, num_tags), dtype = np.int32)\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    test_data  = corpora[i*subset_size:][:subset_size]\n",
    "    train_data = corpora[:i*subset_size] + corpora[(i+1)*subset_size:]\n",
    "    hmm = HMM(train_data, test_data)\n",
    "    hmm.train()\n",
    "    accuracy, confusion_matrix = hmm.evaluation()\n",
    "    \n",
    "    sum_confusion_matrix += confusion_matrix\n",
    "    print(\"\\nEvaluating Fold:{}\".format(i+1))\n",
    "    print(\"Accuracy:{}\".format(accuracy))\n",
    "    if i == 2:\n",
    "        all_tags = hmm.all_tags\n",
    "        print(\"\\nConfusion Matrix for Fold:3\")\n",
    "        print(confusion_matrix)\n",
    "\n",
    "accuracy = np.trace(sum_confusion_matrix)/np.sum(sum_confusion_matrix)\n",
    "accuracy_per_pos = {}\n",
    "recall_per_pos   = {}\n",
    "for idx, tag in enumerate(all_tags):\n",
    "    accuracy_per_pos[tag] = sum_confusion_matrix[idx][idx]/np.sum(sum_confusion_matrix[:, idx])\n",
    "    recall_per_pos[tag]   = sum_confusion_matrix[idx][idx]/np.sum(sum_confusion_matrix[idx, :])\n",
    "print(\"\\nPer POS Accuracy\")\n",
    "print(sorted(accuracy_per_pos.items()))\n",
    "print(\"\\nPer POS Recall for Fold:1\")\n",
    "print(sorted(recall_per_pos.items()))\n",
    "print(\"Average Accuracy:{}\".format(accuracy))\n",
    "\n",
    "print(HMM.unseen_words)\n",
    "print(HMM.unseen_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5557725582909322"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HMM.unseen_correct/HMM.unseen_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
